{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLDgH69sEI89YecBudfPiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dheerajspml/textSummerization/blob/main/Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzugX1ry7pN6"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#   **Project Name:** Text Summerization\n",
        "#  **Author:**Dheeraj Kumar Bharti\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKcXArnUYUl9"
      },
      "source": [
        "**Text Summarization is the process of creating a summary of a certain document which contains the most important information of the original, the purpose of which is to obtain a summary of the main points of the document.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wmIVd6nYrdz"
      },
      "source": [
        "**There is a huge amount of data appearing digitally, so it is necessary to develop a unique procedure to immediately summarize long texts while keeping the main idea. Text summarization also makes it possible to shorten the reading time, speed up information searches and obtain as much information as possible on a subject.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvtbp875_I6G"
      },
      "source": [
        "# **Terms Used:**\n",
        "\n",
        "\n",
        "# *   **Corpus:**A collection of text is known as Corpus. This could be either data sets such as bodies of work by an author, poems by a a particular poet, etc. \n",
        "# *  **Tokenizers:**This divides a text into a series of tokens. In Tokenizers, there are three main tokens – sentence, word, and regex tokenizer. We will be using only the word and the sentence tokenizer.\n",
        "\n",
        "# *   **Stop Words:**Words such as is, an, a, the, for that do not add value to the meaning of a sentence.\n",
        "# *  **sent_tokenize() :**sent_tokenize() method that can be used to create the array of sentences.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZf9dbgZZAfX"
      },
      "source": [
        "# **importing the necessary Python libraries and downloading some necessary package:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d71EgiqUPH6M"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXuBEtJQT-5j",
        "outputId": "19c3bb86-cb54-4bae-f549-688e881ed0d2"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lrNBOZCUHCz",
        "outputId": "cdd32766-ea81-47fe-d3b7-aad6b780ea8e"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HcI6V9vZeDJ"
      },
      "source": [
        "# **My input text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UluoByMqRH_h"
      },
      "source": [
        "text=\"\"\"Various organisations today, be it online shopping, private sector organisations, government, \n",
        "tourism and catering industry, or any other institute that offers customer services, they are all concerned to learn \n",
        "their customer’s feedback each time their services are utilised. Now, consider that these companies are receiving an \n",
        "enormous amount of feedback and data every single day. It becomes quite\n",
        " a tedious task for the management to analyse each of these datapoints and come up with insights.\"\"\"\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tosa-1GbZ-dQ"
      },
      "source": [
        "# finding frequency of each word and storing it into Frequency table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJYQebqEZbuN"
      },
      "source": [
        "#tokenizing the text\n",
        "stopWord=set(stopwords.words(\"english\"))\n",
        "words=word_tokenize(text)\n",
        "#creating frequency table to keep frequency of each word\n",
        "freqTable=dict()\n",
        "for word in words:\n",
        "  word=word.lower()\n",
        "  if word in stopWord:\n",
        "    continue\n",
        "  if word in freqTable:\n",
        "    freqTable[word]+=1\n",
        "  else:\n",
        "    freqTable[word]=1\n",
        "#creating the dictionarry to keep the frequency of each sentence\n",
        "sentences=sent_tokenize(text)\n",
        "sentenceValue=dict()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdNQ3_J3aqqr"
      },
      "source": [
        "# summerizing and printing output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyQL7_GvUeF2",
        "outputId": "0fdd1463-bf63-4275-b15f-966f7266fffa"
      },
      "source": [
        "\n",
        "for sentence in sentences:\n",
        "  for word,freq in freqTable.items():\n",
        "    if word in sentence.lower():\n",
        "      if sentence in sentenceValue:\n",
        "        sentenceValue[sentence]+=freq\n",
        "      else:\n",
        "        sentenceValue[sentence]=freq\n",
        "\n",
        "\n",
        "sumValue=0\n",
        "for sentence in sentenceValue:\n",
        "  sumValue+=sentenceValue[sentence]\n",
        "#average value of sentence from original text\n",
        "average=int(sumValue/len(sentenceValue))\n",
        "summary=''\n",
        "for sentence in sentences:\n",
        "  if(sentence in sentenceValue) and (sentenceValue[sentence]>(1.2*average)):\n",
        "    summary+=\" \"+sentence\n",
        "#printing summerized text\n",
        "print(\"my summerized output:\\n\")\n",
        "print(summary)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my summerized output:\n",
            "\n",
            " Various organisations today, be it online shopping, private sector organisations, government, \n",
            "tourism and catering industry, or any other institute that offers customer services, they are all concerned to learn \n",
            "their customer’s feedback each time their services are utilised.\n"
          ]
        }
      ]
    }
  ]
}